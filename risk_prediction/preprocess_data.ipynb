{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3331fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e002ee62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo '../data/dataset_flights.csv' carregado com sucesso!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Tail_Number</th>\n",
       "      <th>Origin</th>\n",
       "      <th>OriginCityName</th>\n",
       "      <th>Dest</th>\n",
       "      <th>...</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>AirTime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "      <th>DivAirportLandings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>N13161</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>IND</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>N273JB</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>JFK</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-04-13</td>\n",
       "      <td>N258NN</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>CLE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-04-13</td>\n",
       "      <td>N809UA</td>\n",
       "      <td>IAH</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>DFW</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-19</td>\n",
       "      <td>N866AS</td>\n",
       "      <td>SFO</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>ONT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate Tail_Number Origin  \\\n",
       "0  2018        2      4           6          5  2018-04-06      N13161    EWR   \n",
       "1  2018        2      4           6          5  2018-04-06      N273JB    ORD   \n",
       "2  2018        2      4          13          5  2018-04-13      N258NN    ORD   \n",
       "3  2018        2      4          13          5  2018-04-13      N809UA    IAH   \n",
       "4  2018        2      4          19          4  2018-04-19      N866AS    SFO   \n",
       "\n",
       "      OriginCityName Dest  ... Diverted  ActualElapsedTime  AirTime  Distance  \\\n",
       "0         Newark, NJ  IND  ...      0.0              157.0    111.0     645.0   \n",
       "1        Chicago, IL  JFK  ...      0.0              124.0    101.0     740.0   \n",
       "2        Chicago, IL  CLE  ...      0.0               79.0     46.0     316.0   \n",
       "3        Houston, TX  DFW  ...      0.0              230.0     76.0     224.0   \n",
       "4  San Francisco, CA  ONT  ...      0.0               78.0     55.0     363.0   \n",
       "\n",
       "   CarrierDelay  WeatherDelay  NASDelay  SecurityDelay  LateAircraftDelay  \\\n",
       "0          14.0           0.0      13.0            0.0                9.0   \n",
       "1           NaN           NaN       NaN            NaN                NaN   \n",
       "2           NaN           NaN       NaN            NaN                NaN   \n",
       "3           0.0           0.0     142.0            0.0                0.0   \n",
       "4           NaN           NaN       NaN            NaN                NaN   \n",
       "\n",
       "   DivAirportLandings  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path ='../data/dataset_flights.csv'\n",
    "\n",
    "try:\n",
    "    df_main = pd.read_csv(path)\n",
    "    print(f\"Arquivo '{path}' carregado com sucesso!\")\n",
    "    display(df_main.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: O arquivo não foi encontrado em '{path}'. Verifique o caminho e o nome do arquivo.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao carregar o arquivo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaca371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "print(f\"Initial shape: {df_main.shape}\")\n",
    "print(f\"Initial missing values:\\n{df_main.isnull().sum()}\")\n",
    "\n",
    "# ============================================\n",
    "# 1. STANDARDIZE COLUMN HEADERS\n",
    "# ============================================\n",
    "df_main.columns = df_main.columns.str.lower().str.strip().str.replace(' ', '_')\n",
    "\n",
    "# ============================================\n",
    "# 2. STANDARDIZE STRING CONTENT TO LOWERCASE\n",
    "# ============================================\n",
    "str_cols = df_main.select_dtypes(include=['object']).columns\n",
    "for col in str_cols:\n",
    "    df_main[col] = df_main[col].str.lower().str.strip()\n",
    "\n",
    "# ============================================\n",
    "# 3. CONVERT TO DATETIME\n",
    "# ============================================\n",
    "df_main['flightdate'] = pd.to_datetime(df_main['flightdate'])\n",
    "\n",
    "# ============================================\n",
    "# 4. REMOVE CANCELLED AND DIVERTED FLIGHTS\n",
    "# ============================================\n",
    "print(f\"\\nRemoving {df_main['cancelled'].sum()} cancelled flights\")\n",
    "print(f\"Removing {df_main['diverted'].sum()} diverted flights\")\n",
    "\n",
    "df_main = df_main[\n",
    "    (df_main['cancelled'] == 0) &\n",
    "    (df_main['diverted'] == 0)\n",
    "].copy()\n",
    "\n",
    "print(f\"Shape after removing cancelled/diverted: {df_main.shape}\")\n",
    "\n",
    "# ============================================\n",
    "# 5. HANDLE MISSING VALUES\n",
    "# ============================================\n",
    "\n",
    "# Fill delay breakdown columns (only filled when delayed)\n",
    "delay_columns = ['carrierdelay', 'weatherdelay', 'nasdelay',\n",
    "                 'securitydelay', 'lateaircraftdelay']\n",
    "\n",
    "for col in delay_columns:\n",
    "    df_main[col] = df_main[col].fillna(0)\n",
    "\n",
    "# Fill missing delay minutes with 0 (assume on-time if not recorded)\n",
    "df_main['depdelayminutes'] = df_main['depdelayminutes'].fillna(0)\n",
    "df_main['arrdelayminutes'] = df_main['arrdelayminutes'].fillna(0)\n",
    "df_main['arrivaldelaygroups'] = df_main['arrivaldelaygroups'].fillna(0)\n",
    "\n",
    "# Fill missing elapsed time and airtime with median\n",
    "df_main['actualelapsedtime'] = df_main['actualelapsedtime'].fillna(\n",
    "    df_main['actualelapsedtime'].median()\n",
    ")\n",
    "df_main['airtime'] = df_main['airtime'].fillna(\n",
    "    df_main['airtime'].median()\n",
    ")\n",
    "\n",
    "print(f\"\\nMissing values after filling:\\n{df_main.isnull().sum()[df_main.isnull().sum() > 0]}\")\n",
    "\n",
    "# ============================================\n",
    "# 6. DATA QUALITY CHECKS\n",
    "# ============================================\n",
    "\n",
    "# Remove negative delays (data errors)\n",
    "initial_rows = len(df_main)\n",
    "df_main = df_main[\n",
    "    (df_main['depdelayminutes'] >= 0) &\n",
    "    (df_main['arrdelayminutes'] >= 0)\n",
    "].copy()\n",
    "print(f\"\\nRemoved {initial_rows - len(df_main)} rows with negative delays\")\n",
    "\n",
    "# Remove impossible distances\n",
    "initial_rows = len(df_main)\n",
    "df_main = df_main[df_main['distance'] > 0].copy()\n",
    "print(f\"Removed {initial_rows - len(df_main)} rows with invalid distance\")\n",
    "\n",
    "# Cap extreme delays at 6 hours (360 minutes)\n",
    "extreme_delays = (df_main['arrdelayminutes'] > 360).sum()\n",
    "df_main['arrdelayminutes'] = df_main['arrdelayminutes'].clip(upper=360)\n",
    "df_main['depdelayminutes'] = df_main['depdelayminutes'].clip(upper=360)\n",
    "print(f\"Capped {extreme_delays} extreme delays at 360 minutes\")\n",
    "\n",
    "# ============================================\n",
    "# 7. REMOVE DUPLICATES\n",
    "# ============================================\n",
    "initial_rows = len(df_main)\n",
    "df_main = df_main.drop_duplicates()\n",
    "print(f\"Removed {initial_rows - len(df_main)} duplicate rows\")\n",
    "\n",
    "# ============================================\n",
    "# 8. CREATE ROUTE FEATURES\n",
    "# ============================================\n",
    "df_main['flight_route'] = df_main['origincityname'] + ' -> ' + df_main['destcityname']\n",
    "df_main['airport_route'] = df_main['origin'] + ' -> ' + df_main['dest']\n",
    "\n",
    "# ============================================\n",
    "# 9. BASIC TIMESTAMP FEATURES\n",
    "# ============================================\n",
    "df_main['day_name'] = df_main['flightdate'].dt.day_name().str.lower()\n",
    "df_main['is_weekend'] = df_main['flightdate'].dt.dayofweek.isin([5, 6]).astype(int)  # Saturday=5, Sunday=6\n",
    "df_main['week_of_year'] = df_main['flightdate'].dt.isocalendar().week\n",
    "\n",
    "# ============================================\n",
    "# 10. CREATE TARGET VARIABLE (IMPROVED)\n",
    "# ============================================\n",
    "# Binary classification: Delay > 15 minutes (industry standard)\n",
    "df_main['is_delayed'] = (df_main['arrdelayminutes'] > 15).astype(int)\n",
    "\n",
    "# ============================================\n",
    "# 11. ADVANCED TEMPORAL FEATURES\n",
    "# ============================================\n",
    "\n",
    "# US Federal Holidays function\n",
    "def get_us_holidays(year):\n",
    "    \"\"\"Generate US federal holidays for a given year\"\"\"\n",
    "    holidays = []\n",
    "\n",
    "    # Fixed holidays\n",
    "    holidays.append(pd.Timestamp(year, 1, 1))   # New Year's Day\n",
    "    holidays.append(pd.Timestamp(year, 7, 4))   # Independence Day\n",
    "    holidays.append(pd.Timestamp(year, 11, 11)) # Veterans Day\n",
    "    holidays.append(pd.Timestamp(year, 12, 25)) # Christmas\n",
    "\n",
    "    # MLK Day (3rd Monday in January)\n",
    "    jan_mondays = pd.date_range(f'{year}-01-01', f'{year}-01-31', freq='W-MON')\n",
    "    if len(jan_mondays) >= 3:\n",
    "        holidays.append(jan_mondays[2])\n",
    "\n",
    "    # Presidents Day (3rd Monday in February)\n",
    "    feb_mondays = pd.date_range(f'{year}-02-01', f'{year}-02-28', freq='W-MON')\n",
    "    if len(feb_mondays) >= 3:\n",
    "        holidays.append(feb_mondays[2])\n",
    "\n",
    "    # Memorial Day (last Monday in May)\n",
    "    may_mondays = pd.date_range(f'{year}-05-01', f'{year}-05-31', freq='W-MON')\n",
    "    if len(may_mondays) > 0:\n",
    "        holidays.append(may_mondays[-1])\n",
    "\n",
    "    # Labor Day (1st Monday in September)\n",
    "    sep_mondays = pd.date_range(f'{year}-09-01', f'{year}-09-30', freq='W-MON')\n",
    "    if len(sep_mondays) > 0:\n",
    "        holidays.append(sep_mondays[0])\n",
    "\n",
    "    # Columbus Day (2nd Monday in October)\n",
    "    oct_mondays = pd.date_range(f'{year}-10-01', f'{year}-10-31', freq='W-MON')\n",
    "    if len(oct_mondays) >= 2:\n",
    "        holidays.append(oct_mondays[1])\n",
    "\n",
    "    # Thanksgiving (4th Thursday in November)\n",
    "    nov_thursdays = pd.date_range(f'{year}-11-01', f'{year}-11-30', freq='W-THU')\n",
    "    if len(nov_thursdays) >= 4:\n",
    "        holidays.append(nov_thursdays[3])\n",
    "\n",
    "    return holidays\n",
    "\n",
    "# Create holiday list for all years in dataset\n",
    "print(\"\\nGenerating holiday features...\")\n",
    "all_holidays = []\n",
    "for year in df_main['year'].unique():\n",
    "    all_holidays.extend(get_us_holidays(year))\n",
    "\n",
    "all_holidays = set([h.date() for h in all_holidays])\n",
    "\n",
    "# Holiday features\n",
    "df_main['is_holiday'] = df_main['flightdate'].dt.date.isin(all_holidays).astype(int)\n",
    "df_main['days_to_holiday'] = df_main['flightdate'].apply(\n",
    "    lambda x: min([abs((h - x.date()).days) for h in all_holidays])\n",
    ")\n",
    "df_main['is_near_holiday'] = (df_main['days_to_holiday'] <= 3).astype(int)\n",
    "\n",
    "# Day before/after holiday\n",
    "df_main['is_day_before_holiday'] = df_main['flightdate'].apply(\n",
    "    lambda x: (x.date() + timedelta(days=1)) in all_holidays\n",
    ").astype(int)\n",
    "\n",
    "df_main['is_day_after_holiday'] = df_main['flightdate'].apply(\n",
    "    lambda x: (x.date() - timedelta(days=1)) in all_holidays\n",
    ").astype(int)\n",
    "\n",
    "# Season features\n",
    "df_main['is_summer_travel'] = df_main['month'].isin([6, 7, 8]).astype(int)\n",
    "df_main['is_winter_travel'] = df_main['month'].isin([12, 1]).astype(int)\n",
    "df_main['is_spring_break'] = df_main['month'].isin([3, 4]).astype(int)\n",
    "df_main['is_thanksgiving_week'] = (\n",
    "    (df_main['month'] == 11) & (df_main['week_of_year'].isin([47, 48]))\n",
    ").astype(int)\n",
    "df_main['is_christmas_week'] = (\n",
    "    (df_main['month'] == 12) & (df_main['dayofmonth'] >= 20)\n",
    ").astype(int)\n",
    "\n",
    "# Cyclical encoding for temporal features\n",
    "df_main['month_sin'] = np.sin(2 * np.pi * df_main['month'] / 12)\n",
    "df_main['month_cos'] = np.cos(2 * np.pi * df_main['month'] / 12)\n",
    "df_main['dayofweek_sin'] = np.sin(2 * np.pi * df_main['dayofweek'] / 7)\n",
    "df_main['dayofweek_cos'] = np.cos(2 * np.pi * df_main['dayofweek'] / 7)\n",
    "\n",
    "print(f\"Holidays identified: {df_main['is_holiday'].sum()}\")\n",
    "\n",
    "# ============================================\n",
    "# 12. DISTANCE & ROUTE FEATURES\n",
    "# ============================================\n",
    "\n",
    "# Distance categories\n",
    "df_main['distance_category'] = pd.cut(\n",
    "    df_main['distance'],\n",
    "    bins=[0, 500, 1500, 3000, 10000],\n",
    "    labels=['short', 'medium', 'long', 'ultra_long']\n",
    ")\n",
    "\n",
    "# Transcontinental flag\n",
    "df_main['is_transcontinental'] = (df_main['distance'] > 2000).astype(int)\n",
    "\n",
    "# ============================================\n",
    "# 13. FINAL CLEANUP\n",
    "# ============================================\n",
    "\n",
    "# Sort by date for temporal splits\n",
    "df_main = df_main.sort_values('flightdate').reset_index(drop=True)\n",
    "\n",
    "# Ensure all column names are clean\n",
    "df_main.columns = df_main.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# ============================================\n",
    "# 14. SUMMARY\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA CLEANING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final shape: {df_main.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df_main['is_delayed'].value_counts())\n",
    "print(f\"Delay rate: {df_main['is_delayed'].mean():.2%}\")\n",
    "print(f\"\\nDate range: {df_main['flightdate'].min()} to {df_main['flightdate'].max()}\")\n",
    "print(f\"Years: {sorted(df_main['year'].unique())}\")\n",
    "print(f\"\\nMissing values remaining:\")\n",
    "print(df_main.isnull().sum()[df_main.isnull().sum() > 0])\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nFirst few rows after cleaning:\")\n",
    "df_main.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
